The bisarca/robots-txt library is used to model and manage robots.txt files and
directives.

It's based on [An Extended Standard for Robot Exclusion](http://www.conman.org/people/spc/robots2.html) and [Google Robots.txt Specifications](https://developers.google.com/webmasters/control-crawl-index/docs/robots_txt).

![Library Flow](https://www.websequencediagrams.com/cgi-bin/cdraw?lz=dGl0bGUgRmxvdwoKUGFyc2VyLT5SdWxlc2V0czogUGFyc2luZyBmcm9tIGEgZGlydHkgcm9ib3RzLnR4dAoAIggAKAxJbnRlcm5hbC9Vc2VyIGVsYWJvcmF0aW9uACMLQnVpbGRlcjogAAQFaW5nIGEgY2xlYW4AUQw&s=napkin)
